# -*- coding: utf-8 -*-
"""Air Quality.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qfBwc0g220WLup3DXQbhrU45ZPB-1ozD
"""

import tensorflow as tf
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

train_df = pd.read_csv('/content/water_potability.csv')

train_df.head()

train_df.info()

train_df.describe()

train_df['Potability'].value_counts()

plt.hist(train_df['ph'])

plt.hist(train_df['Hardness'])

plt.hist(train_df['Solids'])

plt.hist(train_df['Chloramines'])

plt.hist(train_df['Trihalomethanes'])

train_df.fillna(train_df.mean(), inplace = True)

train_df.info()

sns.pairplot(train_df)

X_train = train_df.drop(['Potability'], 1)
y_train = train_df['Potability']

from sklearn.preprocessing import StandardScaler

scalar = StandardScaler()

train_df_scaled = scalar.fit_transform(X_train)

"""Since the features are non-correlating features, we can use them in the model."""

from tensorflow.python import metrics
#tf.random.set_seed(42)

model = tf.keras.Sequential([tf.keras.layers.Flatten(input_shape=(9,)),
                             tf.keras.layers.Dense(32, activation= 'relu'),
                             #tf.keras.layers.Dense(64, activation= 'relu'),
                             #tf.keras.layers.Dense(128, activation='relu'),
                             #tf.keras.layers.Dense(256, activation='relu'),
                             #tf.keras.layers.Dense(512, activation='relu'),
                             tf.keras.layers.Dense(32, activation='relu'),
                             tf.keras.layers.Dense(1, activation='sigmoid')]
    
)

model.compile(loss=tf.keras.losses.binary_crossentropy,
              optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),
              metrics=[tf.keras.metrics.binary_accuracy,
                       tf.keras.metrics.Precision(name='precision'),
                       tf.keras.metrics.Recall(name='recall')
                       ]
              )


history = model.fit(train_df_scaled, y_train, epochs = 70)

scores = model.evaluate(train_df_scaled, y_train, verbose=0)
scores

x = [11.1, 227.2, 25484.0, 9.0, 404.04, 563.89, 17.93, 71.98, 4.37]
x = np.expand_dims(np.array(x), 0)

x = [8.63, 156.79, 264.03, 8.33, 366888.04, 49552.97, 96.63, 65.60, 4.18]
x = np.expand_dims(np.array(x), 0)

float(model.predict(x, batch_size=1))

float(model.predict(scalar.fit_transform(x), batch_size=2))

print('loss', scores[0])
print('accuracy', scores[1])
print('precision', scores[2])
print('recall', scores[3])

plt.plot(np.arange(1, 71),
         history.history['loss'], label = 'loss')

plt.plot(np.arange(1, 71),
         history.history['binary_accuracy'], label = 'accuracy')

plt.plot(np.arange(1, 71),
         history.history['precision'], label = 'precision')

plt.plot(np.arange(1, 71),
         history.history['recall'], label = 'recall')

plt.title('Evaluation metrics', size=20)
plt.xlabel('Epoch', size = 14)
plt.legend();

"""Save the model as a Pickle file"""

from tensorflow.keras.models import model_from_json

Air_Quality_json = model.to_json()
with open("Air_Quality_json.json", "w") as json_file:
  json_file.write(Air_Quality_json)

#Save the weights
model.save_weights("Air_Quality_weights.h5")
model.save("Air_Quality.h5")

import joblib

air_quality_model = joblib.dump(model, 'AirQuality.pkl')

from sklearn.model_selection import train_test_split

pip install scipy

"""REST API FOR MODEL DEPLOYMENT"""

from flask import Flask, request, redirect, url_for, flash, jsonify
import numpy as np
import pickle as p
import json
import requests

#Load the pretrained model

with open('/content/Air_Quality_json.json', 'r') as f:
  model_json = f.read()

cd /content/

!pip install flask-ngrok
!pip install pyngrok
!pip install ngrok

from pyngrok import ngrok
from flask_ngrok import run_with_ngrok
from flask import Flask, request, render_template
from flask_ngrok import run_with_ngrok
import pickle
import numpy as np
import os

#Set the authentication token from ngrok dashboard
#ngrok.set_auth_token('2F4vrhuhjjjWs9BusfjMmI6eNqX_3srBVgz4qZdtrw7HdwyFS')

#public_url = ngrok.connect(5000).public_url

#print(public_url)

!ngrok authtoken 2F4vrhuhjjjWs9BusfjMmI6eNqX_3srBVgz4qZdtrw7HdwyFS

model = tf.keras.models.load_model('Air_Quality.h5')

from werkzeug.utils import secure_filename

# create a flask app
app = Flask(__name__, template_folder = '/content/')

#run Flask app with ngrok
run_with_ngrok(app)

model = tf.keras.models.load_model('Air_Quality.h5')


#def predict_model(data, model):
#  input = [float(x) for x in request.form.values()[:]]
#  rescaled_input = [np.expand_dims(np.array(input), 0)]
#  final_input = scalar.fit_transform(rescaled_input)
#  prediction = model.predict(final_input, batch_size= 1)

#  return prediction

@app.route('/', methods= ['GET'])
def index():
  return render_template('index.html')

#  return render_template('index(1).html', output = 'Predicted Weight in KGs : {}'.format(prediction))

@app.route('/getprediction', methods = ['GET', 'POST'])
def getprediction():
  if request.method == 'POST':
    input = [float(x) for x in request.form.values()]
    rescaled_input = [np.expand_dims(np.array(input), 0)]
#    final_input = scalar.fit_transform(rescaled_input)
#    prediction = model.predict(final_input, batch_size= 1)
    prediction = model.predict(rescaled_input, batch_size= 1)
    if float(prediction) == 0.0:
      prediction = 'Water is not portable'
    else:
      prediction = 'Water is portable'

    return prediction
  return None


if __name__ == "__main__":
  app.run()









# create a flask app
app = Flask(__name__, template_folder ='template')

#run Flask app with ngrok
run_with_ngrok(app)

@app.route('/profile/<string:name>')

def home(name):
  return render_template('index.html',name=name)

if __name__ == "__main__":
  app.run()

# create a flask app
app = Flask(__name__)

#run Flask app with ngrok
run_with_ngrok(app)

model = tf.keras.models.load_model('Air_Quality.h5')

@app.route('/content')
def home():
  return render_template('index(1).html')

@app.route('/getprediction', methods= ['POST'])
def getprediction(data, model):
  input = [float(x) for x in request.form.values()]
  rescaled_input = [np.expand_dims(np.array(input), 0)]
  final_input = scalar.fit_transform(rescaled_input)
  prediction = model.predict(final_input, batch_size= 1)

  return render_template('index(1).html', output = 'Predicted Weight in KGs : {}'.format(prediction))


if __name__ == "__main__":
  app.run()

app = Flask(__name__)
run_with_ngrok(app)   
  
@app.route("/")
def home():
    return "<h1>Air Quality Prediction Panel</h1>"
    
ph = input("Enter the ph value:", )
Hardness = input("Enter the Hardness value:", )
Solids = input("Enter the Solids value:", )
Chloramines = input("Enter the Chloramines value:", )
Sulfate = input("Enter the Sulfate value:", )
Conductivity = input("Enter the Conductivity value:", )
Organic_carbon = input("Enter the Organic carbon value:", )
Trihalomethanes_Turbidity = input("Enter the Trihalomethanes Turbidity value:", )


app.run()

!ngrok config add-authtoken 2Ez7Zsuh6pjJgHAcl9q3GhjHKge_4VXvwzHUvVMJAU971G8K7

from flask import Flask, request, redirect, url_for, flash, jsonify
import numpy as np
import pickle 
import json
import requests
from scipy.misc import imread, imsave


app = Flask(__name__)

@app.route('/api/', methods=['POST'])

def makecalc():
    data = request.get_json()
    prediction = np.array2string(model.predict(data))

    return jsonify(prediction)

if __name__ == '__main__':
    modelfile = '/content/AirQuality.pkl'
    aq_model = p.load(open(modelfile, 'rb'))
    app.run(debug=True, host='0.0.0.0')

#load the pickle file

#clf_path = '/content/AirQuality.pkl'
#with open(clf_path, 'rb') as f:
#  model.clf = pickle.load(f)

# argument parsing
#parser = reqparse.RequestParser()
#parser.add_argument('query')

class PredictSentiment(Resource):
    def get(self):
        # use parser and find the user's query
        args = parser.parse_args()
        user_query = args['query']

        # vectorize the user's query and make a prediction
        uq_vectorized = model.vectorizer_transform(
            np.array([user_query]))
        prediction = model.predict(uq_vectorized)
        pred_proba = model.predict_proba(uq_vectorized)

        # Output 'Negative' or 'Positive' along with the score
        if prediction == 0:
            pred_text = 'Negative'
        else:
            pred_text = 'Positive'
            
        # round the predict proba value and set to new variable
        confidence = round(pred_proba[0], 3)
        
        # create JSON object
        output = {'prediction': pred_text, 'confidence': confidence}
        
        return output





# Commented out IPython magic to ensure Python compatibility.
!mkdir -p /drive/ngrok-ssh
!mkdir -p /drive/ngrok-ssh/ngrok
# %cd /drive/ngrok-ssh
!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-v3-stable-windows-amd64.zip -O ngrok-v3-stable-windows-amd64.zip
!unzip -u ngrok-v3-stable-windows-amd64.zip
!cp /drive/ngrok-ssh/ngrok /ngrok
!chmod +x /ngrok

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

!mkdir -p /drive
#umount /drive
!mount --bind /content/drive/My\ Drive /drive
!mkdir -p /drive/ngrok-ssh
!mkdir -p ~/.ssh